{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"predict.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"_SONdQuouBGt","colab_type":"text"},"cell_type":"markdown","source":["https://viblo.asia/p/machine-learning-that-thu-vi-8-danh-lua-he-thong-mang-noron-trong-machine-learning-maGK783LZj2\n"]},{"metadata":{"id":"o0x7xt4BnocF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":125},"outputId":"f4770113-8a1f-4bc1-e1d4-32dd1cddff45","executionInfo":{"status":"ok","timestamp":1554704726239,"user_tz":-420,"elapsed":25145,"user":{"displayName":"Võ Hoàng Tú","photoUrl":"","userId":"10850768615639726333"}}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"metadata":{"id":"H98kYP6hnjg7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"226e06f0-0de5-4752-caad-282ef45ece04","executionInfo":{"status":"ok","timestamp":1554707965817,"user_tz":-420,"elapsed":77489,"user":{"displayName":"Võ Hoàng Tú","photoUrl":"","userId":"10850768615639726333"}}},"cell_type":"code","source":["import numpy as np\n","from keras.preprocessing import image\n","from keras.applications import inception_v3\n","\n","# Load pre-trained image recognition model\n","model = inception_v3.InceptionV3()\n","\n","# Load the image file and convert it to a numpy array\n","img = image.load_img(\"/content/gdrive/My Drive/app/hack/hacked-image1.jpg\", target_size=(299, 299))\n","#imghacked = image.load_img(\"/content/gdrive/My Drive/app/hack/hacked-image.png\", target_size=(299, 299))\n","input_image = image.img_to_array(img)\n","#input_image_hacked = image.img_to_array(imghacked)\n","\n","\n","# Scale the image so all pixel intensities are between [-1, 1] as the model expects\n","input_image /= 255.\n","input_image -= 0.5\n","input_image *= 2.\n","\n","# Scale the image so all pixel intensities are between [-1, 1] as the model expects\n","#input_image_hacked /= 255.\n","#input_image_hacked -= 0.5\n","#input_image_hacked *= 2.\n","\n","# Add a 4th dimension for batch size (as Keras expects)\n","input_image = np.expand_dims(input_image, axis=0)\n","\n","# Add a 4th dimension for batch size (as Keras expects)\n","#input_image_hacked = np.expand_dims(input_image_hacked, axis=0)\n","\n","# Run the image through the neural network\n","predictions = model.predict(input_image)\n","\n","# Run the image through the neural network\n","#predictions_hacked = model.predict(input_image_hacked)\n","\n","# Convert the predictions into text and print them\n","predicted_classes = inception_v3.decode_predictions(predictions, top=1)\n","imagenet_id, name, confidence = predicted_classes[0][0]\n","print(\"This is a {} with {:.4}% confidence!\".format(name, confidence * 100))\n","\n","# Convert the predictions into text and print them\n","#predicted_classes_hacked = inception_v3.decode_predictions(predictions_hacked, top=1)\n","#imagenet_id_hacked, name_hacked, confidence_hacked = predicted_classes_hacked[0][0]\n","#print(\"HACKED: This is a {} with {:.4}% confidence!\".format(name_hacked, confidence_hacked * 100))"],"execution_count":12,"outputs":[{"output_type":"stream","text":["This is a Persian_cat with 26.77% confidence!\n"],"name":"stdout"}]}]}