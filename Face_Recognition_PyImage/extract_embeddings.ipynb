{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"extract_embeddings.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"4kKMqK4_Ta8k","colab_type":"code","outputId":"fabab468-dbac-4a13-8057-e4a575b73551","executionInfo":{"status":"ok","timestamp":1552926706693,"user_tz":-420,"elapsed":54305,"user":{"displayName":"Võ Hoàng Tú","photoUrl":"","userId":"10850768615639726333"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"cell_type":"code","source":["!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","from google.colab import auth\n","auth.authenticate_user()\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"],"execution_count":0,"outputs":[{"output_type":"stream","text":["E: Package 'python-software-properties' has no installation candidate\n","··········\n"],"name":"stdout"}]},{"metadata":{"id":"PdqmJjWST8yw","colab_type":"code","outputId":"8d322dda-e549-46fa-c5be-cd8ae349efdc","executionInfo":{"status":"ok","timestamp":1552922608781,"user_tz":-420,"elapsed":2475,"user":{"displayName":"Võ Hoàng Tú","photoUrl":"","userId":"10850768615639726333"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"metadata":{"id":"2tuTwWsYUOg8","colab_type":"code","colab":{}},"cell_type":"code","source":["# import the necessary packages\n","from imutils import paths\n","import numpy as np\n","import argparse\n","import imutils\n","import pickle\n","import cv2\n","import os"],"execution_count":0,"outputs":[]},{"metadata":{"id":"jUrjVcFTUQcR","colab_type":"code","outputId":"59983ed3-3f95-4d6c-f9b3-d4454e368100","executionInfo":{"status":"error","timestamp":1552925028658,"user_tz":-420,"elapsed":4020,"user":{"displayName":"Võ Hoàng Tú","photoUrl":"","userId":"10850768615639726333"}},"colab":{"base_uri":"https://localhost:8080/","height":268}},"cell_type":"code","source":["# load our serialized face detector from disk\n","print(\"[INFO] loading face detector...\")\n","protoPath = os.path.sep.join(['/content/gdrive/My Drive/app/Face_Recognition_PyImage/face_detection_model', \"deploy.prototxt\"])\n","modelPath = os.path.sep.join(['/content/gdrive/My Drive/app/Face_Recognition_PyImage/face_detection_model',\n","\t\"res10_300x300_ssd_iter_140000.caffemodel\"])\n","detector = cv2.dnn.readNetFromCaffe(protoPath, modelPath)\n"," \n","# load our serialized face embedding model from disk\n","print(\"[INFO] loading face recognizer...\")\n","embedder = cv2.dnn.readNetFromTorch('/content/gdrive/My Drive/app/Face_Recognition_PyImage/openface_nn4.small2.v1.t7')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[INFO] loading face detector...\n"],"name":"stdout"},{"output_type":"error","ename":"error","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-0a5fa97aab38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m modelPath = os.path.sep.join(['/content/gdrive/My Drive/app/Face_Recognition_PyImage/face_detection_model',\n\u001b[1;32m      4\u001b[0m \t\"res10_300x300_ssd_iter_140000.caffemodel\"])\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdetector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadNetFromCaffe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotoPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# load our serialized face embedding model from disk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31merror\u001b[0m: OpenCV(3.4.3) /io/opencv/modules/dnn/src/caffe/caffe_io.cpp:1121: error: (-2:Unspecified error) FAILED: fs.is_open(). Can't open \"/content/gdrive/My Drive/app/Face_Recognition_PyImage/face_detection_model/deploy.prototxt\" in function 'ReadProtoFromTextFile'\n"]}]},{"metadata":{"id":"4N-CUymyVRCz","colab_type":"code","outputId":"17dc9a01-7574-44fc-b229-f1623dc2f69d","executionInfo":{"status":"ok","timestamp":1552927912882,"user_tz":-420,"elapsed":23928,"user":{"displayName":"Võ Hoàng Tú","photoUrl":"","userId":"10850768615639726333"}},"colab":{"base_uri":"https://localhost:8080/","height":4437}},"cell_type":"code","source":["# grab the paths to the input images in our dataset\n","print(\"[INFO] quantifying faces...\")\n","imagePaths = list(paths.list_images('/content/gdrive/My Drive/app/Face_Recognition_PyImage/datatqm'))\n","\n","# initialize our lists of extracted facial embeddings and\n","# corresponding people names\n","knownEmbeddings = []\n","knownNames = []\n","\n","# initialize the total number of faces processed\n","total = 0\n","\n","# loop over the image paths\n","for (i, imagePath) in enumerate(imagePaths):\n","\t# extract the person name from the image path\n","\tprint(\"[INFO] processing image {}/{}\".format(i + 1,\n","\t\tlen(imagePaths)))\n","\tname = imagePath.split(os.path.sep)[-2]\n","\n","\t# load the image, resize it to have a width of 600 pixels (while\n","\t# maintaining the aspect ratio), and then grab the image\n","\t# dimensions\n","\timage = cv2.imread(imagePath)\n","\timage = imutils.resize(image, width=600)\n","\t(h, w) = image.shape[:2]\n","\n","\t# construct a blob from the image\n","\timageBlob = cv2.dnn.blobFromImage(\n","\t\tcv2.resize(image, (300, 300)), 1.0, (300, 300),\n","\t\t(104.0, 177.0, 123.0), swapRB=False, crop=False)\n","\n","\t# apply OpenCV's deep learning-based face detector to localize\n","\t# faces in the input image\n","\tdetector.setInput(imageBlob)\n","\tdetections = detector.forward()\n","\n","\t# ensure at least one face was found\n","\tif len(detections) > 0:\n","\t\t# we're making the assumption that each image has only ONE\n","\t\t# face, so find the bounding box with the largest probability\n","\t\ti = np.argmax(detections[0, 0, :, 2])\n","\t\tconfidence = detections[0, 0, i, 2]\n","\n","\t\t# ensure that the detection with the largest probability also\n","\t\t# means our minimum probability test (thus helping filter out\n","\t\t# weak detections)\n","\t\tif confidence > 0.5:\n","\t\t\t# compute the (x, y)-coordinates of the bounding box for\n","\t\t\t# the face\n","\t\t\tbox = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n","\t\t\t(startX, startY, endX, endY) = box.astype(\"int\")\n","\n","\t\t\t# extract the face ROI and grab the ROI dimensions\n","\t\t\tface = image[startY:endY, startX:endX]\n","\t\t\t(fH, fW) = face.shape[:2]\n","\n","\t\t\t# ensure the face width and height are sufficiently large\n","\t\t\tif fW < 20 or fH < 20:\n","\t\t\t\tcontinue\n","\n","\t\t\t# construct a blob for the face ROI, then pass the blob\n","\t\t\t# through our face embedding model to obtain the 128-d\n","\t\t\t# quantification of the face\n","\t\t\tfaceBlob = cv2.dnn.blobFromImage(face, 1.0 / 255,\n","\t\t\t\t(96, 96), (0, 0, 0), swapRB=True, crop=False)\n","\t\t\tembedder.setInput(faceBlob)\n","\t\t\tvec = embedder.forward()\n","\n","\t\t\t# add the name of the person + corresponding face\n","\t\t\t# embedding to their respective lists\n","\t\t\tknownNames.append(name)\n","\t\t\tknownEmbeddings.append(vec.flatten())\n","\t\t\ttotal += 1\n","\n","# dump the facial embeddings + names to disk\n","print(\"[INFO] serializing {} encodings...\".format(total))\n","data = {\"embeddings\": knownEmbeddings, \"names\": knownNames}\n","f = open('/content/gdrive/My Drive/app/Face_Recognition_PyImage/output1/encodings123.pickle', \"wb\")\n","f.write(pickle.dumps(data))\n","f.close()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[INFO] quantifying faces...\n","[INFO] processing image 1/258\n","[INFO] processing image 2/258\n","[INFO] processing image 3/258\n","[INFO] processing image 4/258\n","[INFO] processing image 5/258\n","[INFO] processing image 6/258\n","[INFO] processing image 7/258\n","[INFO] processing image 8/258\n","[INFO] processing image 9/258\n","[INFO] processing image 10/258\n","[INFO] processing image 11/258\n","[INFO] processing image 12/258\n","[INFO] processing image 13/258\n","[INFO] processing image 14/258\n","[INFO] processing image 15/258\n","[INFO] processing image 16/258\n","[INFO] processing image 17/258\n","[INFO] processing image 18/258\n","[INFO] processing image 19/258\n","[INFO] processing image 20/258\n","[INFO] processing image 21/258\n","[INFO] processing image 22/258\n","[INFO] processing image 23/258\n","[INFO] processing image 24/258\n","[INFO] processing image 25/258\n","[INFO] processing image 26/258\n","[INFO] processing image 27/258\n","[INFO] processing image 28/258\n","[INFO] processing image 29/258\n","[INFO] processing image 30/258\n","[INFO] processing image 31/258\n","[INFO] processing image 32/258\n","[INFO] processing image 33/258\n","[INFO] processing image 34/258\n","[INFO] processing image 35/258\n","[INFO] processing image 36/258\n","[INFO] processing image 37/258\n","[INFO] processing image 38/258\n","[INFO] processing image 39/258\n","[INFO] processing image 40/258\n","[INFO] processing image 41/258\n","[INFO] processing image 42/258\n","[INFO] processing image 43/258\n","[INFO] processing image 44/258\n","[INFO] processing image 45/258\n","[INFO] processing image 46/258\n","[INFO] processing image 47/258\n","[INFO] processing image 48/258\n","[INFO] processing image 49/258\n","[INFO] processing image 50/258\n","[INFO] processing image 51/258\n","[INFO] processing image 52/258\n","[INFO] processing image 53/258\n","[INFO] processing image 54/258\n","[INFO] processing image 55/258\n","[INFO] processing image 56/258\n","[INFO] processing image 57/258\n","[INFO] processing image 58/258\n","[INFO] processing image 59/258\n","[INFO] processing image 60/258\n","[INFO] processing image 61/258\n","[INFO] processing image 62/258\n","[INFO] processing image 63/258\n","[INFO] processing image 64/258\n","[INFO] processing image 65/258\n","[INFO] processing image 66/258\n","[INFO] processing image 67/258\n","[INFO] processing image 68/258\n","[INFO] processing image 69/258\n","[INFO] processing image 70/258\n","[INFO] processing image 71/258\n","[INFO] processing image 72/258\n","[INFO] processing image 73/258\n","[INFO] processing image 74/258\n","[INFO] processing image 75/258\n","[INFO] processing image 76/258\n","[INFO] processing image 77/258\n","[INFO] processing image 78/258\n","[INFO] processing image 79/258\n","[INFO] processing image 80/258\n","[INFO] processing image 81/258\n","[INFO] processing image 82/258\n","[INFO] processing image 83/258\n","[INFO] processing image 84/258\n","[INFO] processing image 85/258\n","[INFO] processing image 86/258\n","[INFO] processing image 87/258\n","[INFO] processing image 88/258\n","[INFO] processing image 89/258\n","[INFO] processing image 90/258\n","[INFO] processing image 91/258\n","[INFO] processing image 92/258\n","[INFO] processing image 93/258\n","[INFO] processing image 94/258\n","[INFO] processing image 95/258\n","[INFO] processing image 96/258\n","[INFO] processing image 97/258\n","[INFO] processing image 98/258\n","[INFO] processing image 99/258\n","[INFO] processing image 100/258\n","[INFO] processing image 101/258\n","[INFO] processing image 102/258\n","[INFO] processing image 103/258\n","[INFO] processing image 104/258\n","[INFO] processing image 105/258\n","[INFO] processing image 106/258\n","[INFO] processing image 107/258\n","[INFO] processing image 108/258\n","[INFO] processing image 109/258\n","[INFO] processing image 110/258\n","[INFO] processing image 111/258\n","[INFO] processing image 112/258\n","[INFO] processing image 113/258\n","[INFO] processing image 114/258\n","[INFO] processing image 115/258\n","[INFO] processing image 116/258\n","[INFO] processing image 117/258\n","[INFO] processing image 118/258\n","[INFO] processing image 119/258\n","[INFO] processing image 120/258\n","[INFO] processing image 121/258\n","[INFO] processing image 122/258\n","[INFO] processing image 123/258\n","[INFO] processing image 124/258\n","[INFO] processing image 125/258\n","[INFO] processing image 126/258\n","[INFO] processing image 127/258\n","[INFO] processing image 128/258\n","[INFO] processing image 129/258\n","[INFO] processing image 130/258\n","[INFO] processing image 131/258\n","[INFO] processing image 132/258\n","[INFO] processing image 133/258\n","[INFO] processing image 134/258\n","[INFO] processing image 135/258\n","[INFO] processing image 136/258\n","[INFO] processing image 137/258\n","[INFO] processing image 138/258\n","[INFO] processing image 139/258\n","[INFO] processing image 140/258\n","[INFO] processing image 141/258\n","[INFO] processing image 142/258\n","[INFO] processing image 143/258\n","[INFO] processing image 144/258\n","[INFO] processing image 145/258\n","[INFO] processing image 146/258\n","[INFO] processing image 147/258\n","[INFO] processing image 148/258\n","[INFO] processing image 149/258\n","[INFO] processing image 150/258\n","[INFO] processing image 151/258\n","[INFO] processing image 152/258\n","[INFO] processing image 153/258\n","[INFO] processing image 154/258\n","[INFO] processing image 155/258\n","[INFO] processing image 156/258\n","[INFO] processing image 157/258\n","[INFO] processing image 158/258\n","[INFO] processing image 159/258\n","[INFO] processing image 160/258\n","[INFO] processing image 161/258\n","[INFO] processing image 162/258\n","[INFO] processing image 163/258\n","[INFO] processing image 164/258\n","[INFO] processing image 165/258\n","[INFO] processing image 166/258\n","[INFO] processing image 167/258\n","[INFO] processing image 168/258\n","[INFO] processing image 169/258\n","[INFO] processing image 170/258\n","[INFO] processing image 171/258\n","[INFO] processing image 172/258\n","[INFO] processing image 173/258\n","[INFO] processing image 174/258\n","[INFO] processing image 175/258\n","[INFO] processing image 176/258\n","[INFO] processing image 177/258\n","[INFO] processing image 178/258\n","[INFO] processing image 179/258\n","[INFO] processing image 180/258\n","[INFO] processing image 181/258\n","[INFO] processing image 182/258\n","[INFO] processing image 183/258\n","[INFO] processing image 184/258\n","[INFO] processing image 185/258\n","[INFO] processing image 186/258\n","[INFO] processing image 187/258\n","[INFO] processing image 188/258\n","[INFO] processing image 189/258\n","[INFO] processing image 190/258\n","[INFO] processing image 191/258\n","[INFO] processing image 192/258\n","[INFO] processing image 193/258\n","[INFO] processing image 194/258\n","[INFO] processing image 195/258\n","[INFO] processing image 196/258\n","[INFO] processing image 197/258\n","[INFO] processing image 198/258\n","[INFO] processing image 199/258\n","[INFO] processing image 200/258\n","[INFO] processing image 201/258\n","[INFO] processing image 202/258\n","[INFO] processing image 203/258\n","[INFO] processing image 204/258\n","[INFO] processing image 205/258\n","[INFO] processing image 206/258\n","[INFO] processing image 207/258\n","[INFO] processing image 208/258\n","[INFO] processing image 209/258\n","[INFO] processing image 210/258\n","[INFO] processing image 211/258\n","[INFO] processing image 212/258\n","[INFO] processing image 213/258\n","[INFO] processing image 214/258\n","[INFO] processing image 215/258\n","[INFO] processing image 216/258\n","[INFO] processing image 217/258\n","[INFO] processing image 218/258\n","[INFO] processing image 219/258\n","[INFO] processing image 220/258\n","[INFO] processing image 221/258\n","[INFO] processing image 222/258\n","[INFO] processing image 223/258\n","[INFO] processing image 224/258\n","[INFO] processing image 225/258\n","[INFO] processing image 226/258\n","[INFO] processing image 227/258\n","[INFO] processing image 228/258\n","[INFO] processing image 229/258\n","[INFO] processing image 230/258\n","[INFO] processing image 231/258\n","[INFO] processing image 232/258\n","[INFO] processing image 233/258\n","[INFO] processing image 234/258\n","[INFO] processing image 235/258\n","[INFO] processing image 236/258\n","[INFO] processing image 237/258\n","[INFO] processing image 238/258\n","[INFO] processing image 239/258\n","[INFO] processing image 240/258\n","[INFO] processing image 241/258\n","[INFO] processing image 242/258\n","[INFO] processing image 243/258\n","[INFO] processing image 244/258\n","[INFO] processing image 245/258\n","[INFO] processing image 246/258\n","[INFO] processing image 247/258\n","[INFO] processing image 248/258\n","[INFO] processing image 249/258\n","[INFO] processing image 250/258\n","[INFO] processing image 251/258\n","[INFO] processing image 252/258\n","[INFO] processing image 253/258\n","[INFO] processing image 254/258\n","[INFO] processing image 255/258\n","[INFO] processing image 256/258\n","[INFO] processing image 257/258\n","[INFO] processing image 258/258\n","[INFO] serializing 0 encodings...\n"],"name":"stdout"}]},{"metadata":{"id":"8kRg74fuWi19","colab_type":"text"},"cell_type":"markdown","source":["Train face recognition model"]},{"metadata":{"id":"F2J5AZg-WnnO","colab_type":"code","colab":{}},"cell_type":"code","source":["# import the necessary packages\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.svm import SVC\n","import argparse\n","import pickle"],"execution_count":0,"outputs":[]},{"metadata":{"id":"DXLHO-C6WwF9","colab_type":"code","outputId":"c7920ade-dd8f-4319-98c9-d0c406abd5b2","executionInfo":{"status":"ok","timestamp":1552928397211,"user_tz":-420,"elapsed":959,"user":{"displayName":"Võ Hoàng Tú","photoUrl":"","userId":"10850768615639726333"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"cell_type":"code","source":["# load the face embeddings\n","print(\"[INFO] loading face embeddings...\")\n","data = pickle.loads(open('/content/gdrive/My Drive/app/Face_Recognition_PyImage/output1/embeddings.pickle', \"rb\").read())\n","#with open('/content/gdrive/My Drive/app/Face_Recognition_PyImage/output1/embeddings.pickle', 'rb') as my_dump_file:\n"," #   data = pickle.load(my_dump_file)\n","  #  data = np.array(data)\n","\n","# encode the labels\n","print(\"[INFO] encoding labels...\")\n","le = LabelEncoder()\n","labels = le.fit_transform(data[\"names\"])\n","# train the model used to accept the 128-d embeddings of the face and\n","# then produce the actual face recognition\n","print(\"[INFO] training model...\")\n","recognizer = SVC(C=1.0, kernel=\"linear\", probability=True)\n","recognizer.fit(data[\"embeddings\"], labels)\n","\n","\n","# write the actual face recognition model to disk\n","f = open('/content/gdrive/My Drive/app/Face_Recognition_PyImage/output1/recognizer.pickle', \"wb\")\n","f.write(pickle.dumps(recognizer))\n","f.close()\n"," \n","# write the label encoder to disk\n","f = open('/content/gdrive/My Drive/app/Face_Recognition_PyImage/output1/le.pickle', \"wb\")\n","f.write(pickle.dumps(le))\n","f.close()\n","print(\"finish!\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[INFO] loading face embeddings...\n","[INFO] encoding labels...\n","[INFO] training model...\n","finish!\n"],"name":"stdout"}]}]}